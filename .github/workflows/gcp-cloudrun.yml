name: Deploy to Google Cloud Run

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: europe-west2                      # London region equivalent
  SERVICE_NAME: arzani-marketplace
  NODE_VERSION: '20.x'                      # Updated to latest LTS
  
  # Database configuration for Google Cloud SQL
  DB_INSTANCE: arzani-marketplace-db-v17
  DB_NAME: arzani_marketplace
  DB_USER: marketplace_user
  
  # Image configuration
  IMAGE_NAME: arzani-marketplace
  REGISTRY: europe-west2-docker.pkg.dev

permissions:
  contents: read
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    # Install system dependencies for canvas and native modules
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential libcairo2-dev libpango1.0-dev libjpeg-dev libgif-dev librsvg2-dev
        sudo apt-get install -y python3 make g++ node-gyp

    # Authenticate to Google Cloud
    - name: Authenticate to Google Cloud
      id: auth
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

    # Setup Google Cloud CLI
    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2
      with:
        project_id: ${{ env.PROJECT_ID }}

    # Verify and set PROJECT_ID if missing
    - name: Verify and set PROJECT_ID
      run: |
        echo "ğŸ” Checking PROJECT_ID configuration..."
        echo "PROJECT_ID from env: '${{ env.PROJECT_ID }}'"
        echo "PROJECT_ID from secret: '${{ secrets.GCP_PROJECT_ID }}'"
        
        # If PROJECT_ID is empty, try to get it from gcloud
        if [ -z "${{ env.PROJECT_ID }}" ] || [ "${{ env.PROJECT_ID }}" = "" ]; then
          echo "âš ï¸ PROJECT_ID is empty, trying to detect from gcloud..."
          DETECTED_PROJECT=$(gcloud config get-value project 2>/dev/null || echo "")
          if [ -n "$DETECTED_PROJECT" ]; then
            echo "âœ… Detected project ID: $DETECTED_PROJECT"
            echo "PROJECT_ID=$DETECTED_PROJECT" >> $GITHUB_ENV
          else
            echo "âŒ Could not detect project ID. Setting fallback value..."
            echo "PROJECT_ID=cool-mile-437217-s2" >> $GITHUB_ENV
          fi
        else
          echo "âœ… PROJECT_ID is set: ${{ env.PROJECT_ID }}"
        fi

    # Configure Docker for Google Cloud
    - name: Configure Docker
      run: |
        gcloud auth configure-docker ${{ env.REGISTRY }}

    # Install dependencies
    - name: Install dependencies
      run: |
        npm ci --production=false
        
    # Fix permissions for native modules
    - name: Fix native module permissions
      run: |
        # Set proper permissions for bcrypt and other native modules
        if [ -d "node_modules" ]; then
          chmod -R 755 node_modules/
          echo "Fixed node_modules permissions"
        fi
        
        # Ensure all binaries are executable
        if [ -d "node_modules/.bin" ]; then
          find node_modules/.bin -type f -exec chmod +x {} \;
          echo "Fixed binary permissions"
        fi
        
    # Fix TailwindCSS CLI permissions
    - name: Make Tailwind CLI executable
      run: |
        if [ -f "./node_modules/.bin/tailwindcss" ]; then
          chmod +x ./node_modules/.bin/tailwindcss
          echo "TailwindCSS binary made executable"
        else
          echo "TailwindCSS binary not found, will use npx"
        fi
        
    # Run tests
    - name: Run tests
      run: |
        npm test
      env:
        NODE_ENV: test
        TEST_DATABASE_URL: ${{ secrets.TEST_DATABASE_URL }}
        JWT_SECRET: ${{ secrets.JWT_SECRET }}

    # Build application
    - name: Build application
      run: |
        npm run build --if-present
      env:
        NODE_ENV: production

    # Debug: Check workspace contents before production build
    - name: Debug workspace contents
      run: |
        echo "ğŸ” Debugging workspace contents before production build..."
        echo "ğŸ“‚ Current directory: $(pwd)"
        echo "ğŸ“‹ Root directory contents:"
        ls -la | head -20
        echo ""
        echo "ğŸ“„ Looking for critical files:"
        [ -f "package.json" ] && echo "âœ… package.json found" || echo "âŒ package.json NOT found"
        [ -f "server.js" ] && echo "âœ… server.js found" || echo "âŒ server.js NOT found"
        [ -f "app.js" ] && echo "âœ… app.js found" || echo "âš ï¸ app.js not found (optional)"
        [ -f "db.js" ] && echo "âœ… db.js found" || echo "âš ï¸ db.js not found (optional)"
        echo ""
        echo "ğŸ“ Checking for directories:"
        for dir in public views routes middleware libs services scripts migrations utils socket; do
          if [ -d "$dir" ]; then
            echo "âœ… $dir directory found"
          else
            echo "âš ï¸ $dir directory not found"
          fi
        done

    # Create optimized production build
    - name: Prepare production files
      shell: bash
      run: |
        set -e  # Exit on any error
        
        echo "ğŸ”¨ Starting production build preparation..."
        
        # Show current directory and contents for debugging
        echo "ğŸ“‚ Current working directory: $(pwd)"
        echo "ğŸ“‹ Files in root directory:"
        ls -la | head -20
        
        # Create production directory
        mkdir -p production
        echo "âœ… Created production directory"
        
        # Verify essential files exist before copying
        echo "ğŸ” Checking for essential files..."
        
        if [ ! -f "package.json" ]; then
          echo "âŒ ERROR: package.json not found in root directory"
          echo "ğŸ“‹ Available files:"
          ls -la *.json 2>/dev/null || echo "No JSON files found"
          exit 1
        fi
        
        if [ ! -f "server.js" ]; then
          echo "âŒ ERROR: server.js not found in root directory"
          echo "ğŸ“‹ Available JS files:"
          ls -la *.js 2>/dev/null || echo "No JS files found"
          exit 1
        fi
        
        echo "âœ… Essential files verified"
        
        # Copy package files first (critical files)
        echo "ğŸ“¦ Copying package files..."
        cp package*.json production/
        echo "âœ… Copied package*.json files"
        
        # Copy server.js (main application file)
        echo "ğŸ–¥ï¸ Copying server.js..."
        cp server.js production/
        echo "âœ… Copied server.js"
        
        # Copy other essential root files
        echo "ğŸ“„ Copying other essential files..."
        for file in app.js db.js config.js; do
          if [ -f "$file" ]; then
            cp "$file" production/
            echo "âœ… Copied $file"
          else
            echo "âš ï¸ Optional file $file not found, skipping"
          fi
        done
        
        # Copy application directories
        echo "ğŸ“ Copying application directories..."
        for dir in public views routes middleware libs services scripts migrations utils socket; do
          if [ -d "$dir" ]; then
            cp -r "$dir" production/
            echo "âœ… Copied $dir directory"
          else
            echo "âš ï¸ Directory $dir not found, skipping"
          fi
        done
        
        # Copy any additional JavaScript files in root
        echo "ğŸ“œ Copying additional JavaScript files..."
        find . -maxdepth 1 -name "*.js" -not -name "server.js" -not -path "./node_modules/*" -not -path "./.git/*" -not -path "./production/*" -exec cp {} production/ \; 2>/dev/null || true
        echo "âœ… Copied additional JavaScript files"
        
        # CRITICAL: Verify production directory has required files
        echo "ğŸ” Verifying production build..."
        
        if [ ! -d "production" ]; then
          echo "âŒ CRITICAL ERROR: Production directory was not created"
          exit 1
        fi
        
        if [ ! -f "production/package.json" ]; then
          echo "âŒ CRITICAL ERROR: package.json not found in production directory"
          echo "ğŸ“‹ Production directory contents:"
          ls -la production/
          exit 1
        fi
        
        if [ ! -f "production/server.js" ]; then
          echo "âŒ CRITICAL ERROR: server.js not found in production directory"
          echo "ğŸ“‹ Production directory contents:"
          ls -la production/
          exit 1
        fi
        
        echo "âœ… Production build verification successful"
        echo "ğŸ“Š Production directory contents:"
        ls -la production/ | head -20
        
        # Move to production directory for dependency installation
        cd production
        
        # Backup and modify package.json to remove postinstall script
        if [ -f "package.json" ]; then
          cp package.json package.json.backup
          echo "ğŸ“‹ Removing postinstall script from package.json..."
          node -e "
            try {
              const pkg = JSON.parse(require('fs').readFileSync('package.json', 'utf8'));
              if (pkg.scripts && pkg.scripts.postinstall) {
                delete pkg.scripts.postinstall;
                require('fs').writeFileSync('package.json', JSON.stringify(pkg, null, 2));
                console.log('âœ… Removed postinstall script');
              } else {
                console.log('âš ï¸ No postinstall script found');
              }
            } catch (e) {
              console.log('âš ï¸ Could not modify package.json:', e.message);
            }
          "
        fi
        
        # Install only production dependencies
        echo "ğŸ“¦ Installing production dependencies..."
        npm ci --only=production --silent
        echo "âœ… Installed production dependencies"
        
        # Fix permissions for production node_modules
        if [ -d "node_modules" ]; then
          chmod -R 755 node_modules/
          echo "âœ… Fixed production node_modules permissions"
        fi
        
        if [ -d "node_modules/.bin" ]; then
          find node_modules/.bin -type f -exec chmod +x {} \;
          echo "âœ… Fixed production binary permissions"
        fi
        
        # Return to root directory
        cd ..
        
        # Clean up unnecessary files to reduce image size
        echo "ğŸ§¹ Cleaning up production build..."
        rm -rf production/node_modules/.cache 2>/dev/null || true
        find production -name "*.test.js" -delete 2>/dev/null || true
        find production -name "*.spec.js" -delete 2>/dev/null || true
        find production -name "test" -type d -exec rm -rf {} + 2>/dev/null || true
        
        echo "âœ… Production build preparation completed successfully"
        echo "ğŸ“Š Final production directory size:"
        du -sh production/ 2>/dev/null || echo "Could not calculate size"
        
        echo "ğŸ¯ Final verification - critical files present:"
        [ -f "production/package.json" ] && echo "âœ… production/package.json" || echo "âŒ production/package.json MISSING"
        [ -f "production/server.js" ] && echo "âœ… production/server.js" || echo "âŒ production/server.js MISSING"

    # Create Dockerfile for Cloud Run
    - name: Create Dockerfile
      run: |
        cat > Dockerfile << 'EOF'
        # Use official Node.js runtime with long-term support
        FROM node:20-alpine
        
        # Install system dependencies for canvas, native modules, and health checks
        RUN apk add --no-cache \
            cairo-dev \
            pango-dev \
            jpeg-dev \
            giflib-dev \
            librsvg-dev \
            build-base \
            python3 \
            make \
            g++ \
            curl \
            dumb-init
        
        # Set the working directory
        WORKDIR /app
        
        # Copy package files first for better Docker layer caching
        COPY production/package*.json ./
        
        # Install app dependencies
        RUN npm ci --only=production --silent && npm cache clean --force
        
        # Copy app source code
        COPY production/ .
        
        # Create non-root user for security
        RUN addgroup -g 1001 -S nodejs && \
            adduser -S nodejs -u 1001
        
        # Change ownership of the app directory to nodejs user
        RUN chown -R nodejs:nodejs /app
        
        # Switch to non-root user
        USER nodejs
        
        # Expose the port that Cloud Run expects
        EXPOSE 8080
        
        # Add health check
        HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
          CMD curl -f http://localhost:8080/health || exit 1
        
        # Set environment variable for Cloud Run
        ENV NODE_ENV=production
        ENV PORT=8080
        
        # Use dumb-init to handle signals properly in containers
        ENTRYPOINT ["dumb-init", "--"]
        
        # Start the application
        CMD ["node", "server.js"]
        EOF
        
        echo "âœ… Dockerfile created successfully"
        cat Dockerfile

    # Build and push Docker image
    - name: Build and push Docker image
      run: |
        # Hardcoded image configuration (no environment variables needed)
        PROJECT_ID="cool-mile-437217-s2"
        REGISTRY="europe-west2-docker.pkg.dev"
        REPO_NAME="arzani-marketplace"
        IMAGE_NAME="arzani-marketplace"
        GITHUB_SHA="${{ github.sha }}"
        
        # Construct image URIs manually with correct Artifact Registry format
        IMAGE_URI="${REGISTRY}/${PROJECT_ID}/${REPO_NAME}/${IMAGE_NAME}:${GITHUB_SHA}"
        LATEST_URI="${REGISTRY}/${PROJECT_ID}/${REPO_NAME}/${IMAGE_NAME}:latest"
        
        echo "ğŸ³ Docker Image Configuration (Hardcoded):"
        echo "PROJECT_ID: $PROJECT_ID"
        echo "REGISTRY: $REGISTRY"
        echo "REPO_NAME: $REPO_NAME"
        echo "IMAGE_NAME: $IMAGE_NAME"
        echo "GITHUB_SHA: $GITHUB_SHA"
        echo "IMAGE_URI: $IMAGE_URI"
        echo "LATEST_URI: $LATEST_URI"
        
        # Verify Docker authentication
        echo "ğŸ” Configuring Docker authentication..."
        gcloud auth configure-docker ${REGISTRY} --quiet
        
        # Verify production directory exists and has content
        echo "ğŸ“ Verifying production directory..."
        ls -la production/ | head -10
        echo "ğŸ“¦ Production package.json main field:"
        grep -A1 -B1 '"main"' production/package.json || echo "No main field found"
        
        # Build image with explicit platform for Cloud Run compatibility
        echo "ğŸ—ï¸ Building Docker image for linux/amd64 platform..."
        docker build --platform linux/amd64 -t ${IMAGE_URI} .
        
        # Verify the image was built successfully
        echo "âœ… Verifying Docker image was built..."
        docker images | grep ${IMAGE_NAME} || echo "âš ï¸ No images found with name pattern"
        
        # Test basic container functionality
        echo "ğŸ§ª Testing Docker image..."
        docker run --rm ${IMAGE_URI} node --version
        
        # Push image
        echo "ğŸ“¤ Pushing Docker image..."
        docker push ${IMAGE_URI}
        
        # Also tag as latest
        echo "ğŸ·ï¸ Tagging and pushing as latest..."
        docker tag ${IMAGE_URI} ${LATEST_URI}
        docker push ${LATEST_URI}
        
        # Export for later steps (use hardcoded values)
        echo "IMAGE_URI=${IMAGE_URI}" >> $GITHUB_ENV
        echo "âœ… Docker build and push completed successfully"

    # Check/Create Cloud SQL instance
    - name: Setup Cloud SQL database
      run: |
        # Check if Cloud SQL instance exists
        if ! gcloud sql instances describe ${{ env.DB_INSTANCE }} --quiet 2>/dev/null; then
          echo "Creating Cloud SQL instance..."
          gcloud sql instances create ${{ env.DB_INSTANCE }} \
            --database-version=POSTGRES_17 \
            --tier=db-custom-1-3840 \
            --region=${{ env.REGION }} \
            --storage-type=SSD \
            --storage-size=10GB \
            --backup-start-time=03:00 \
            --maintenance-window-day=SUN \
            --maintenance-window-hour=04 \
            --deletion-protection
            
          echo "Waiting for instance to be ready..."
          gcloud sql instances patch ${{ env.DB_INSTANCE }} --quiet
          
          # Create database
          gcloud sql databases create ${{ env.DB_NAME }} --instance=${{ env.DB_INSTANCE }}
          
          # Create user
          gcloud sql users create ${{ env.DB_USER }} \
            --instance=${{ env.DB_INSTANCE }} \
            --password=${{ secrets.DB_PASSWORD }}
            
          echo "Cloud SQL instance created successfully"
        else
          echo "Cloud SQL instance already exists"
        fi
        
        # Get connection name for Cloud Run
        CONNECTION_NAME=$(gcloud sql instances describe ${{ env.DB_INSTANCE }} --format="value(connectionName)")
        echo "DB_CONNECTION_NAME=$CONNECTION_NAME" >> $GITHUB_ENV

    # Verify environment variables are present
    - name: Check required environment variables
      run: |
        echo "ğŸ” Verifying all required environment variables are available..."
        
        # Track missing variables
        missing_vars=""
        required_vars="DB_PASSWORD JWT_SECRET STRIPE_SECRET_KEY OPENAI_API_KEY"
        
        # Check each required secret (using indirect variable access for security)
        for var in $required_vars; do
          case $var in
            "DB_PASSWORD")
              if [ -z "${{ secrets.DB_PASSWORD }}" ]; then
                missing_vars="$missing_vars $var"
              fi
              ;;
            "JWT_SECRET")
              if [ -z "${{ secrets.JWT_SECRET }}" ]; then
                missing_vars="$missing_vars $var"
              fi
              ;;
            "STRIPE_SECRET_KEY")
              if [ -z "${{ secrets.STRIPE_SECRET_KEY }}" ]; then
                missing_vars="$missing_vars $var"
              fi
              ;;
            "OPENAI_API_KEY")
              if [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
                missing_vars="$missing_vars $var"
              fi
              ;;
          esac
        done
        
        # Report results
        if [ -n "$missing_vars" ]; then
          echo "âŒ Missing required environment variables:$missing_vars"
          echo ""
          echo "ğŸ”§ To fix this issue:"
          echo "1. Go to your GitHub repository"
          echo "2. Click on 'Settings' tab"
          echo "3. Click on 'Secrets and variables' â†’ 'Actions'"
          echo "4. Add the following repository secrets:"
          for var in $missing_vars; do
            echo "   â€¢ $var"
          done
          echo ""
          echo "ğŸ’¡ Required values:"
          echo "   â€¢ DB_PASSWORD: Password for your PostgreSQL database"
          echo "   â€¢ JWT_SECRET: Secret key for JWT token signing (generate a strong random string)"
          echo "   â€¢ STRIPE_SECRET_KEY: Your Stripe secret key from Stripe dashboard"
          echo "   â€¢ OPENAI_API_KEY: Your OpenAI API key from OpenAI platform"
          exit 1
        fi
        
        echo "âœ… All required environment variables are available"
        echo "ğŸ”’ Using GitHub Secrets for secure environment variable management"

    # Deploy to Cloud Run
    - name: Deploy to Cloud Run
      run: |
        # Deploy the service
        gcloud run deploy ${{ env.SERVICE_NAME }} \
          --image=${{ env.IMAGE_URI }} \
          --region=${{ env.REGION }} \
          --platform=managed \
          --allow-unauthenticated \
          --port=8080 \
          --memory=1Gi \
          --cpu=1 \
          --min-instances=0 \
          --max-instances=10 \
          --timeout=300 \
          --concurrency=100 \
          --add-cloudsql-instances=${{ env.DB_CONNECTION_NAME }} \
          --set-env-vars="NODE_ENV=production" \
          --set-env-vars="DATABASE_URL=postgresql://${{ env.DB_USER }}:${{ secrets.DB_PASSWORD }}@localhost:5432/${{ env.DB_NAME }}?host=/cloudsql/${{ env.DB_CONNECTION_NAME }}" \
          --set-env-vars="JWT_SECRET=${{ secrets.JWT_SECRET }}" \
          --set-env-vars="STRIPE_SECRET_KEY=${{ secrets.STRIPE_SECRET_KEY }}" \
          --set-env-vars="OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" \
          --set-env-vars="A2A_AUTH_ENABLED=false" \
          --set-env-vars="DATABASE_SSL=false"

    # Get service URL
    - name: Get service URL
      run: |
        SERVICE_URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} --region=${{ env.REGION }} --format="value(status.url)")
        echo "SERVICE_URL=$SERVICE_URL" >> $GITHUB_ENV
        echo "ğŸš€ Application deployed to: $SERVICE_URL"

    # Verify deployment
    - name: Verify deployment
      run: |
        # Wait a moment for the service to be ready
        sleep 10
        
        # Test health endpoint
        if curl -f ${{ env.SERVICE_URL }}/health; then
          echo "âœ… Deployment successful!"
          echo "ğŸŒ Application URL: ${{ env.SERVICE_URL }}"
          echo "ğŸ—„ï¸ Database: Cloud SQL PostgreSQL"
          echo "ğŸ“Š Monitoring: Available in Google Cloud Console"
        else
          echo "âš ï¸ Deployment completed but health check failed"
          echo "Check logs: gcloud run services logs read ${{ env.SERVICE_NAME }} --region=${{ env.REGION }}"
        fi

    # Output deployment information
    - name: Deployment Summary
      run: |
        echo "==================== DEPLOYMENT SUMMARY ===================="
        echo "âœ… Successfully migrated from AWS to Google Cloud Run!"
        echo ""
        echo "ğŸŒ Application URL: ${{ env.SERVICE_URL }}"
        echo "ğŸ—„ï¸ Database: Cloud SQL PostgreSQL in ${{ env.REGION }}"
        echo "ğŸ³ Container: ${{ env.IMAGE_URI }}"
        echo "ğŸ“Š Monitoring: Google Cloud Console"
        echo ""
        echo "ğŸ”— Access your application:"
        echo "   â€¢ Main site: ${{ env.SERVICE_URL }}"
        echo "   â€¢ Health check: ${{ env.SERVICE_URL }}/health"
        echo "   â€¢ Admin: ${{ env.SERVICE_URL }}/admin"
        echo ""
        echo "ğŸ’° Cost Benefits vs AWS:"
        echo "   â€¢ Pay-per-request pricing (vs EC2 always-on)"
        echo "   â€¢ Automatic scaling to zero"
        echo "   â€¢ No instance management overhead"
        echo "   â€¢ Integrated with Cloud SQL (managed PostgreSQL)"
        echo ""
        echo "ğŸ“‹ Next Steps:"
        echo "   1. Update your domain DNS to point to Cloud Run URL"
        echo "   2. Set up custom domain in Cloud Run console"
        echo "   3. Configure SSL certificate (automatic with custom domain)"
        echo "   4. Set up monitoring and alerting"
        echo "=============================================================="
